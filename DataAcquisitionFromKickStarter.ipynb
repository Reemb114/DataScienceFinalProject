{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f44825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import concurrent.futures\n",
    "import random\n",
    "import psutil\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d08ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_driver():\n",
    "    \n",
    "    PROXY = \"p.webshare.io:9999\"\n",
    "    webdriver.DesiredCapabilities.FIREFOX['proxy'] = {\n",
    "    \"httpProxy\": PROXY,\n",
    "    \"sslProxy\": PROXY,\n",
    "    \"proxyType\": \"MANUAL\",\n",
    "    }\n",
    "    \n",
    "    firefox_driver_path = \"/Users/reembeniluz/Downloads/geckodriver\"  # Replace with the actual path to the GeckoDriver executable\n",
    "    options = Options()\n",
    "    options.add_argument('-headless')\n",
    "    options.add_argument(\"--private\")\n",
    "    driver = webdriver.Firefox(service=Service(firefox_driver_path), options=options)\n",
    "    print(\"Driver was created\")\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(url):\n",
    "    driver = initialize_driver()\n",
    "    driver.get(url)\n",
    "    time.sleep(random.randint(2, 4))\n",
    "    links = []\n",
    "    extract_project_links(driver, links)\n",
    "    driver.quit()\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_project_links(driver, links):\n",
    "    page_links = driver.execute_script(\"\"\"\n",
    "        const elements = document.querySelectorAll('div.relative.self-start a[href].block.img-placeholder.w100p');\n",
    "        const filteredLinks = [];\n",
    "        elements.forEach(element => {\n",
    "            const href = element.getAttribute('href');\n",
    "            if (!href.includes('ref=recommendation-no-result-discoverpage')) {\n",
    "                filteredLinks.push(href);\n",
    "            }\n",
    "        });\n",
    "        return filteredLinks;\n",
    "    \"\"\")\n",
    "    links.extend(page_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c29f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def projects_links_list_from_website(url, start_page, end_page, links,seed):\n",
    "    page_seed = seed\n",
    "    for seed_count in range(1, 5):\n",
    "        page_urls = [url.replace(f'page={start_page}', f'page={page}') for page in range(start_page, end_page+1)]\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=12) as executor:\n",
    "            futures = [executor.submit(scrape_page, page_url) for page_url in page_urls]\n",
    "\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                result = future.result()\n",
    "                print(result)\n",
    "                links.extend(result)\n",
    "                future.done()\n",
    "\n",
    "            url = url.replace(f'seed={page_seed}', f'seed={page_seed+1}')\n",
    "            page_seed += 1\n",
    "        for future in futures:\n",
    "            future.result()\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_project_data(link,driver):\n",
    "    driver.get(link)\n",
    "    time.sleep(10)\n",
    "    try:\n",
    "        element = driver.find_element(By.XPATH, '//*[@id=\"react-project-header\"]')\n",
    "        days_left_element = driver.find_element(By.XPATH, '/html/body/main/div/div/div[1]/div/div[1]/div[1]/div[2]/div[2]/div[3]/div/div/span[1]')\n",
    "        data_initial = element.get_attribute(\"data-initial\")\n",
    "        json_data = json.loads(data_initial)\n",
    "        project_name = json_data['project']['name']\n",
    "        project_link = link\n",
    "        currency = json_data['project']['currency']\n",
    "        location = json_data['project']['location']['displayableName']\n",
    "        try:\n",
    "            parent_category = json_data['project']['category']['parentCategory']['name']\n",
    "        except:\n",
    "            parent_category = 'none'\n",
    "        category_name = json_data['project']['category']['name']\n",
    "        is_project_we_love = json_data['project']['isProjectWeLove']\n",
    "        percent_funded = json_data['project']['percentFunded']\n",
    "        goal_amount = json_data['project']['goal']['amount']\n",
    "        pledged_amount = json_data['project']['pledged']['amount']\n",
    "        duration = json_data['project']['duration']\n",
    "        description_length = len(json_data['project']['description'])\n",
    "        video_elements = driver.find_elements(By.TAG_NAME, \"video\")\n",
    "        video_count = len(video_elements)\n",
    "        image_elements = driver.find_elements(By.TAG_NAME, \"img\")\n",
    "        image_count = len(image_elements)\n",
    "        days_left = days_left_element.text\n",
    "\n",
    "        try:\n",
    "            riskField = driver.find_element(By.XPATH, '//*[@id=\"risks-and-challenges\"]/p')\n",
    "            riskDescLength = len(riskField.text)\n",
    "        except:\n",
    "            riskDescLength = 0\n",
    "            \n",
    "        project_info = {\n",
    "        \"Project Link\":project_link,\n",
    "        \"Project Name\": project_name,\n",
    "        \"Currency\": currency,\n",
    "        \"Location\": location,\n",
    "        \"Parent Category\": parent_category,\n",
    "        \"Category Name\": category_name,\n",
    "        \"Is Project We Love\": is_project_we_love,\n",
    "        \"Percent Funded\": percent_funded,\n",
    "        \"Goal Amount\": goal_amount,\n",
    "        \"Pledged Amount\": pledged_amount,\n",
    "        \"Duration\": duration,\n",
    "        \"Description Length\": description_length,\n",
    "        \"Image Count\": image_count,\n",
    "        \"Video Count\": video_count,\n",
    "        \"Risk Desc Count\": riskDescLength,\n",
    "        \"Days Left\":days_left\n",
    "    }\n",
    "    except:\n",
    "        print(\"problem with link\", link)\n",
    "\n",
    "\n",
    "    return project_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projects_data_from_links(links,project_data_dic):\n",
    "    counter = 1\n",
    "\n",
    "    def scrape_project_data_wrapper(link):\n",
    "        driver = initialize_driver()\n",
    "        try:\n",
    "            return scrape_project_data(link,driver)\n",
    "        finally:\n",
    "            print(\"Driver Quited\")\n",
    "            driver.quit()\n",
    "            time.sleep(20)\n",
    "            \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        futures = [executor.submit(scrape_project_data_wrapper, link) for link in links]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                project_data_dic.append(result)\n",
    "                print('finished with project:', counter)\n",
    "                counter += 1\n",
    "            except:\n",
    "                print('skipping link')\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6082e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv_table(data, filename):\n",
    "    fieldnames = [\n",
    "        \"Project Name\",\n",
    "        \"Project Link\",\n",
    "        \"Parent Category\",\n",
    "        \"Category Name\",\n",
    "        \"Location\",\n",
    "        \"Currency\",\n",
    "        \"Goal Amount\",\n",
    "        \"Pledged Amount\",\n",
    "        \"Percent Funded\",\n",
    "        \"Duration\",\n",
    "        \"Days Left\",\n",
    "        \"Description Length\",\n",
    "        \"Risk Desc Count\",\n",
    "        \"Is Project We Love\",\n",
    "        \"Image Count\",\n",
    "        \"Video Count\"\n",
    "    ]\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206ab9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_list():\n",
    "    with open(\"ProjectsLinks.txt\", \"r\") as file:\n",
    "        # Read the content of the file and store each line as an element in the list\n",
    "        links = file.readlines()\n",
    "        # Remove trailing newline characters from each line\n",
    "        links = [link.strip() for link in links]\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd24cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_urls_to_file(url_list, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for url in url_list:\n",
    "            file.write(url + '\\n')\n",
    "    print(f\"URLs saved to '{filename}' successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce6ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_into_dict(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc68eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_dicts(data):\n",
    "    unique_data = []\n",
    "    unique_project_links = set()\n",
    "    for row in data:\n",
    "        project_link = row['Project Link']\n",
    "        if project_link not in unique_project_links:\n",
    "            unique_data.append(row)\n",
    "            unique_project_links.add(project_link)\n",
    "    return unique_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d89f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2 = load_csv_into_dict('projects_table_data_final1.csv')\n",
    "unique_data = remove_duplicate_dicts(dict2)\n",
    "print(len(unique_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7815790",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_table(unique_data,'projects_table_data_final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a5cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]\n",
    "project_data_dic = []\n",
    "url = \"https://www.kickstarter.com/discover/advanced?woe_id=Earth&sort=end_date&seed=2809206&page=1\"\n",
    "projects_links_list_from_website(url,1,200,links,2809206)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d5217",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_data_from_links(links,project_data_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b9c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_table(project_data_dic,'projects_table_data600.csv')\n",
    "print('table was created successfuly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8824de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2dd347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
